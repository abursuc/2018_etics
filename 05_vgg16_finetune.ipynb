{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a dense layer to VGG\n",
    "\n",
    "The last layer of Vgg16 outputs a vector of 1000 categories, because that is the number of categories the competition asked for. Of these categories, some of them certainly correspond to cats and dogs, but at a much more granular level (specific breeds).\n",
    "\n",
    "We will simply add a Dense layer on top of the imagenet layer, and train the model to map the imagenet classifications of input images of cats and dogs to cat and dog labels.\n",
    "\n",
    "Note that this is not what we have been doing in the very first lecture!\n",
    "\n",
    "Note also that this approach is closely related to Exercise 2 of last lecture.\n",
    "\n",
    "Have a look at [CS231n: Linear Classification](http://cs231n.github.io/linear-classify/) for more precisions and especially to [CS231n: Softmax classifier](http://cs231n.github.io/linear-classify/#softmax) if you had trouble with Exercise 2 of last lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets\n",
    "import torch\n",
    "import bcolz\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "import utils; imp.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first precompute the outputs of Vgg16 model on our dataset and store these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print('Using gpu: %s ' % use_gpu)\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "if use_gpu:\n",
    "    dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_dir = '/home/ubuntu/data/dogscats'\n",
    "data_dir = '/moldo/lectures/2018_etics/practicals/sample'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize paths for dataset items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), prep1)\n",
    "         for x in ['train', 'valid']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running on CPU, you will probably need to lower the size of the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "batch_size = 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize data loader that will fetch images from disk using num_workers parallel threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=batch_size,\n",
    "                                               shuffle=shuffle_valtrain(x), num_workers=6)\n",
    "                for x in ['train', 'valid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_sizes = {x: len(dsets[x]) for x in ['train', 'valid']}\n",
    "dset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate VGG16 model pretrained on ImageNet from the ```torchvision``` model Zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vgg = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    model_vgg = model_vgg.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default all the modules are initialized to train mode (```self.training = True```). Also be aware that some layers have different behavior during train/and evaluation (like _BatchNorm_, _Dropout_) so setting it matters.\n",
    "\n",
    "Also as a rule of thumb for programming in general, try to explicitly state your intent and set ```model.train()``` and ```model.eval()``` when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for extracting and storing CNN features, i.e. the ouput of VGG16 model in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prefeat(dataset):\n",
    "    features = []\n",
    "    labels_list = []\n",
    "    for data in dataset:\n",
    "        inputs,labels = data\n",
    "        if use_gpu:\n",
    "            inputs , labels = Variable(inputs.cuda()),Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs , labels = Variable(inputs),Variable(labels)\n",
    "        \n",
    "        x = model_vgg(inputs)\n",
    "        features.extend(x.data.cpu().numpy())\n",
    "        labels_list.extend(labels.data.cpu().numpy())\n",
    "    features = np.concatenate([[feat] for feat in features])\n",
    "    return (features,labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "feat_train,labels_train = prefeat(dset_loaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and resizing the images every time we want to use them isn't necessary - instead we should save the processed arrays. By far the fastest way to save and load numpy arrays is using bcolz. This also compresses the arrays, so we save disk space. Here are the functions we'll use to save and load using bcolz (already loaded above...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(os.path.join(data_dir,'vgg16','feat_train.bc'),feat_train)\n",
    "save_array(os.path.join(data_dir,'vgg16','lbs_train.bc',labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "feat_val,lbs_val = prefeat(dset_loaders['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(os.path.join(data_dir,'vgg16','feat_val.bc'),feat_val)\n",
    "save_array(os.path.join(data_dir,'vgg16','lbs_val.bc'),lbs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_train = load_array(os.path.join(data_dir,'vgg16','feat_train.bc'))\n",
    "lbs_train = load_array(os.path.join(data_dir,'vgg16','lbs_train.bc'))\n",
    "feat_val = load_array(os.path.join(data_dir,'vgg16','feat_val.bc'))\n",
    "lbs_val = load_array(os.path.join(data_dir,'vgg16','lbs_val.bc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear model for VGG16 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to define our linear model.\n",
    "\n",
    "For more details about the [cross entropy cost function](http://neuralnetworksanddeeplearning.com/chap3.html#the_cross-entropy_cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1000, 2),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss(size_average=False)\n",
    "if use_gpu:\n",
    "    lm = lm.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our features are currently stacked in a _numpy ndarray_, we will define a custom data loader to fetch random samples from it and group them in batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(feat,labels,batch_size=64,shuffle=True):\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    if shuffle:\n",
    "        # generate a random index to simulate shuffling of the data\n",
    "        index = np.random.permutation(len(feat))\n",
    "        feat = feat[index]\n",
    "        labels = labels[index]\n",
    "    for idx in range(0,len(feat),batch_size):\n",
    "        yield(feat[idx:idx+batch_size],labels[idx:idx+batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define next a holistic training function (```train_model```) that will:\n",
    "- run for a pre-defined number of epochs/iterations\n",
    "- fetch training samples randomly during each epoch(all samples are used during an epoch)\n",
    "- pass samples through network, compute error, gradients and updates network parameters\n",
    "- keep and print training statistics: training loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model,size,feat=None,labels=None,epochs=1,optimizer=None,batch_size=64,shuffle=True):\n",
    "    model.train()\n",
    "    loss_t = np.zeros(epochs)\n",
    "    acc_t = np.zeros(epochs)\n",
    "    for epoch in range(epochs):\n",
    "        batches = get_batches(feat=feat,labels=labels,batch_size=batch_size,shuffle=shuffle)\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs,classes in batches:\n",
    "            if use_gpu:\n",
    "                inputs , classes = Variable(torch.from_numpy(inputs).cuda()),Variable(torch.from_numpy(classes).cuda())\n",
    "            else:\n",
    "                inputs , classes = Variable(torch.from_numpy(inputs)),Variable(torch.from_numpy(classes))\n",
    "                \n",
    "            inputs = inputs.view(inputs.size(0), -1)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs,classes)           \n",
    "            if optimizer is None:\n",
    "                raise ValueError('Pass optimizer for train mode')\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            # statistics\n",
    "            running_loss += loss.data[0]\n",
    "            running_corrects += torch.sum(preds == classes.data)\n",
    "        epoch_loss = running_loss / size\n",
    "        epoch_acc = running_corrects / size\n",
    "        #print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "        loss_t[epoch] = epoch_loss\n",
    "        acc_t[epoch] = epoch_acc\n",
    "    print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "    return loss_t, acc_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set our hyperparameters:\n",
    "- learning rate\n",
    "- optimizer to be used for gradient descent, here SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer_lm = torch.optim.SGD(lm.parameters(), lr=learning_rate)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our model for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loss1, acc1 = (train_model(model=lm,size=dset_sizes['train'],feat=feat_train,labels=lbs_train,\n",
    "            epochs=num_epochs,optimizer=optimizer_lm,batch_size = 64,shuffle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the evolution of the training loss across epochs. \n",
    "\n",
    "Ideally is should have a steep descent in the first epochs, then decrease smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the evolution of the accuracy of our model on the training data. The behavior resembles globally to the one of the loss: big improvement at the beginning, then smaller improvements as training advances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __loss__ helps the network to learn and update the parameters according to the criterion that we give to the network.\n",
    "\n",
    "The __accuracy__ on the other hand is a performance metric for the task for which we want to use the network for. In many cases the accuracy cannot be integrated as a loss/criterion function, so we need to identify or design loss functions that will guide the model towards the behavior we wish to have for our task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we let the model train for 100 additional epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loss2, acc2 = train_model(model=lm,size=dset_sizes['train'],feat=feat_train,labels=lbs_train,\n",
    "                          epochs=num_epochs,optimizer=optimizer_lm,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we plot the loss and accuracy for the current training interval: _epochs[100:200]_.\n",
    "What changes do you notice? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model train for 100 more epochs and plot the evolution of our training indicators. \n",
    "How are they evolving comparing to the previous runs?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "loss3, acc3 = (train_model(model=lm,size=dset_sizes['train'],feat=feat_train,labels=lbs_train,\n",
    "            epochs=num_epochs,optimizer=optimizer_lm,shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define next a holistic test function (```test_model```) that will:\n",
    "- fetch test samples\n",
    "- pass samples through network, compute error, accuracy and confusion matrix\n",
    "- keep and print test statistics: test loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model,size,feat=None,labels=None,batch_size=64):\n",
    "    model.eval()\n",
    "    batches = get_batches(feat=feat,labels=labels,batch_size=batch_size,shuffle=False)\n",
    "    predictions = np.zeros(size)\n",
    "    conf = np.zeros((size,2))\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    count = 0 \n",
    "    for inputs,classes in batches:\n",
    "        if use_gpu:\n",
    "            inputs , classes = Variable(torch.from_numpy(inputs).cuda()),Variable(torch.from_numpy(classes).cuda())\n",
    "        else:\n",
    "            inputs , classes = Variable(torch.from_numpy(inputs)),Variable(torch.from_numpy(classes))\n",
    "                \n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs,classes)           \n",
    "        _,preds = torch.max(outputs.data,1)\n",
    "        # statistics\n",
    "        running_loss += loss.data[0]\n",
    "        running_corrects += torch.sum(preds == classes.data)\n",
    "        #print(count, 'Loss: {:.4f} Acc: {:.4f}'.format( loss.data[0]/ batch_size,\n",
    "        #                                               torch.sum(preds == classes.data) / batch_size))\n",
    "        if use_gpu:\n",
    "            predictions[count*batch_size:(count+1)*batch_size] = preds.cpu().numpy()\n",
    "            conf[count*batch_size:(count+1)*batch_size,:] = outputs.data.cpu().numpy()\n",
    "        else:\n",
    "            predictions[count*batch_size:(count+1)*batch_size] = preds.numpy()\n",
    "            conf[count*batch_size:(count+1)*batch_size,:] = outputs.data.numpy()\n",
    "        count +=1\n",
    "        \n",
    "    print('Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects / size))\n",
    "    return predictions, conf, running_loss / size, running_corrects / size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate on the test data a snapshot of our model at _epoch #300_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "preds, conf, loss_val, acc_val = (test_model(model=lm,size=dset_sizes['valid'],feat=feat_val,labels=lbs_val,batch_size=2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quantitative analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate the training losses across the 300 training epochs and plot them along with the loss on the test data using a snapshot of our model at epoch #300.\n",
    "\n",
    "What do you notice? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.concatenate((loss1, loss2, loss3)))\n",
    "plt.plot(loss_val.numpy()*np.ones(300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We illustrate a similar plot for the training loss values at _epochs[200:300]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss3)\n",
    "plt.plot(loss_val.numpy()*np.ones(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now illustrate the aggregated training accuracies on epochs[0:300] along with the test accuracy for the model at epoch #300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.concatenate((acc1, acc2, acc3)))\n",
    "plt.plot(acc_val.numpy()*np.ones(300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our model for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loss4, acc4 = (train_model(model=lm,size=dset_sizes['train'],feat=feat_train,labels=lbs_train,\n",
    "            epochs=1000,optimizer=optimizer_lm,shuffle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the model snapshot at _epoch #1300_ and keep its statiscs and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds2, conf2, loss_val2, acc_val2 = (test_model(model=lm,size=dset_sizes['valid'],feat=feat_val,labels=lbs_val,batch_size=2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aggregate train loss values at _epochs[300:1300]_ and test loss at _epochs[300]_ and _epochs[1300]_.\n",
    "Do you notice a trend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.concatenate((loss3,loss4)))\n",
    "plt.plot(np.concatenate((loss_val.numpy()*np.ones(100),loss_val2.numpy()*np.ones(1000))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A similar plot for the accuracy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.concatenate((acc1, acc2, acc3, acc4)))\n",
    "plt.plot(np.concatenate((acc_val.numpy()*np.ones(300),acc_val2.numpy()*np.ones(1000))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "What is happening?\n",
    "\n",
    "My plots are ugly and perhaps even misleading! \n",
    "\n",
    "Make better plots on which we see the evolution of the loss/accuracy on both the training and validation sets as a function of the number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Viewing model prediction (qualitative analysis)\n",
    "\n",
    "The most important metrics for us to look at are for the validation set, since we want to check for over-fitting.\n",
    "\n",
    "With our first model we should try to overfit before we start worrying about how to handle that - there's no point even thinking about regularization, data augmentation, etc if you're still under-fitting! (We'll be looking at these techniques after the 2 weeks break...)\n",
    "\n",
    "\n",
    "As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n",
    "\n",
    "   1. A few correct labels at random\n",
    "   2. A few incorrect labels at random\n",
    "   3. The most correct labels of each class (ie those with highest probability that are correct)\n",
    "   4. The most incorrect labels of each class (ie those with highest probability that are incorrect)\n",
    "   5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "\n",
    "In general, these are particularly useful for debugging problems in the model. Since our model is very simple, there may not be too much to learn at this stage..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of images to view for each visualization task\n",
    "n_view = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = np.where(preds==lbs_val)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import random, permutation\n",
    "idx = permutation(correct)[:n_view]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_correct = torch.utils.data.DataLoader([dsets['valid'][x] for x in idx],batch_size = n_view,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in dataset_correct:\n",
    "    inputs_cor,labels_cor = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs_cor)\n",
    "\n",
    "imshow(out, title=[x for x in labels_cor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "for x in idx:\n",
    "    display(Image(filename=dsets['valid'].imgs[x][0], retina=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(preds!=lbs_val)[0]\n",
    "for x in permutation(incorrect)[:n_view]:\n",
    "    print(dsets['valid'].imgs[x][1])\n",
    "    display(Image(filename=dsets['valid'].imgs[x][0], retina=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((preds==0) & (preds==lbs_val))[0]\n",
    "most_correct_cats = np.argsort(conf[correct_cats,1])[:n_view]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in most_correct_cats:\n",
    "    display(Image(filename=dsets['valid'].imgs[correct_cats[x]][0], retina=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((preds==1) & (preds==lbs_val))[0]\n",
    "most_correct_dogs = np.argsort(conf[correct_dogs,0])[:n_view]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in most_correct_dogs:\n",
    "    display(Image(filename=dsets['valid'].imgs[correct_dogs[x]][0], retina=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise\n",
    "\n",
    "As seen in the first lecture, the last layer of Vgg16 is simply a dense layer that outputs 1000 elements. Therefore, it seems somewhat unreasonable to stack a dense layer meant to find cats and dogs on top of one that's meant to find imagenet categories, in that we're limiting the information available to us by first coercing the neural network to classify to imagenet before cats and dogs...\n",
    "\n",
    "Instead, do finetuning, i.e remove that last layer and add on a new layer for cats and dogs. \n",
    "\n",
    "Compare to what we did in the first lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
